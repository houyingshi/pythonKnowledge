{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_bytes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPZhVgA88I8O4wVogCWFhDO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PjNO1OkfCUS"
      },
      "source": [
        "\n",
        "一、字符串的表示和存储\n",
        "\n",
        "字符串是字符的序列，每个字符都有有一个数字作为标识，同时会有一个将标识转换为存储字节的编码方案；\n",
        "\n",
        "\n",
        "```\n",
        "s = 'hello world python'\n",
        "for c in s:\n",
        "  print(c, end=' ')\n",
        "```\n",
        "\n",
        "`h e l l o   w o r l d   p y t h o n`\n",
        "\n",
        "ACSII为协议内的每个字符分别对应一个数字，然后以这个数字的二进制形式存储到计算机;\n",
        "\n",
        "```\n",
        "s = 'hello world python'\n",
        "\n",
        "for c in s: \n",
        "  num = ord(c)\n",
        "  print(num, format(num, 'b'))\n",
        "```\n",
        "\n",
        "```\n",
        "104 1101000\n",
        "101 1100101\n",
        "108 1101100\n",
        "108 1101100\n",
        "111 1101111\n",
        "32 100000\n",
        "119 1110111\n",
        "111 1101111\n",
        "114 1110010\n",
        "108 1101100\n",
        "100 1100100\n",
        "32 100000\n",
        "112 1110000\n",
        "121 1111001\n",
        "116 1110100\n",
        "104 1101000\n",
        "111 1101111\n",
        "110 1101110\n",
        "```\n",
        "\n",
        "ACSII协议覆盖的字符十分有限，使用一个字节就可以保存，这也是其比较简单的根源；\n",
        "\n",
        "```\n",
        "s = b'é'\n",
        "```\n",
        "```\n",
        "  File \"<ipython-input-19-b82fcf157fe5>\", line 1\n",
        "    s = b'é'\n",
        "       ^\n",
        "SyntaxError: bytes can only contain ASCII literal characters.\n",
        "```\n",
        "\n",
        "unicode标准为每个字符制定一个数字作为code point；\n",
        "```\n",
        "s = 'è ç í'\n",
        "for c in s:\n",
        "  print(ord(c))\n",
        "```\n",
        "```\n",
        "232\n",
        "32\n",
        "231\n",
        "32\n",
        "237\n",
        "```\n",
        "\n",
        "unicode支持大量的字符，需要使用多个字节来存储，这就涉及到字节的大小端、空间占用及与ACSII的兼容性问题；\n",
        "\n",
        "UTF-32编码方案直接使用4个字节来承载code poin的二进制形式，涉及大小端问题，比较浪费空间，使用较少；\n",
        "\n",
        "```\n",
        "s = 'èçí'\n",
        "\n",
        "for b in s.encode('utf_32be'):\n",
        "  print(hex(b), end=' ')\n",
        "\n",
        "print()\n",
        "for b in s.encode('utf_32le'):\n",
        "  print(hex(b), end=' ')\n",
        "\n",
        "print()\n",
        "for b in s.encode('utf_32'):\n",
        "  print(hex(b), end=' ')\n",
        "```\n",
        "\n",
        "```\n",
        "0x0 0x0 0x0 0xe8 0x0 0x0 0x0 0xe7 0x0 0x0 0x0 0xed \n",
        "0xe8 0x0 0x0 0x0 0xe7 0x0 0x0 0x0 0xed 0x0 0x0 0x0 \n",
        "0xff 0xfe 0x0 0x0 0xe8 0x0 0x0 0x0 0xe7 0x0 0x0 0x0 0xed 0x0 0x0 0x0 \n",
        "```\n",
        "\n",
        "UTF-16编码方案根据前两个字节的范围来确定使用两个字节还是四个字节，虽然比UTF-32节省空间，但是使用也比较少；\n",
        "```\n",
        "s = 'èçí'\n",
        "\n",
        "for b in s.encode('utf_16be'):\n",
        "  print(hex(b), end=' ')\n",
        "\n",
        "print()\n",
        "for b in s.encode('utf_16le'):\n",
        "  print(hex(b), end=' ')\n",
        "\n",
        "print()\n",
        "for b in s.encode('utf_16'):\n",
        "  print(hex(b), end=' ')\n",
        "```\n",
        "\n",
        "```\n",
        "0x0 0xe8 0x0 0xe7 0x0 0xed \n",
        "0xe8 0x0 0xe7 0x0 0xed 0x0 \n",
        "0xff 0xfe 0xe8 0x0 0xe7 0x0 0xed 0x0 \n",
        "```\n",
        "UTF-8也使用变长字节，每个字符使用的字节个数与其Unicode编号的大小有关，编号小的使用的字节就少，编号大的使用的字节就多，使用的字节个数为1～4不等；\n",
        "```\n",
        "s = 'èçí'\n",
        "\n",
        "for b in s.encode('utf_8'):\n",
        "  print(hex(b), end=' ')\n",
        "```\n",
        "```\n",
        "0xc3 0xa8 0xc3 0xa7 0xc3 0xad \n",
        "```\n",
        "\n",
        "utf-16和utf-32编码方案默认生成的字节序列会添加BOM(byte-order mark)即\\xff\\xfe，指明编码的时候使用Interl CPU小字节序。\n",
        "\n",
        "二、字节数组\n",
        "bytes和bytearray的元素都是介于0-255之间的整数，但是通过字符编码方案也可以存储任何的字符串；字节数组切片还是对应的字节数组；\n",
        "字节数组可以直接显示ASCII字符；\n",
        "```\n",
        "s = 'helloèçí'\n",
        "b_arr = bytes(s, 'utf_8')\n",
        "print(type(b_arr))\n",
        "print(type(b_arr))\n",
        "for b in b_arr:\n",
        "  print(b, end=' ')\n",
        "\n",
        "print()\n",
        "print('element of bytes is int number', b_arr[0])\n",
        "\n",
        "print('splice of bytes is bytes',end = ' ' )\n",
        "b_arr_splice = b_arr[:1]\n",
        "print(b_arr_splice)\n",
        "\n",
        "num_b_arr = bytes([299])\n",
        "```\n",
        "```\n",
        "<class 'bytes'>\n",
        "b'hello\\xc3\\xa8\\xc3\\xa7\\xc3\\xad'\n",
        "104 101 108 108 111 195 168 195 167 195 173 \n",
        "element of bytes is int number 104\n",
        "splice of bytes is bytes b'h'\n",
        "---------------------------------------------------------------------------\n",
        "ValueError                                Traceback (most recent call last)\n",
        "<ipython-input-61-b8f064f91cf5> in <module>()\n",
        "     13 print(b_arr_splice)\n",
        "     14 \n",
        "---> 15 num_b_arr = bytes([299])\n",
        "\n",
        "ValueError: bytes must be in range(0, 256)\n",
        "```\n",
        "\n",
        "struct模块提供了一些函数，把打包的字节序列转换成不同类型字段组成的元组，还有一些函数用于执行反向转换，把元组转换成打包的字节序列。struct模块能处理bytes、bytearray和memoryview对象。\n",
        "```\n",
        "import struct\n",
        "record_format = 'hd4s'\n",
        "pack_bytes = struct.pack(record_format, 7 , 3.14,b'gbye')\n",
        "print(type(pack_bytes))\n",
        "print(pack_bytes)\n",
        "with open('struct.b', 'wb') as fp:\n",
        "  fp.write(pack_bytes)\n",
        "\n",
        "record_size = struct.calcsize(record_format)\n",
        "with open('struct.b', 'rb') as fp:\n",
        "  record_bs = fp.read(record_size)\n",
        "  print(struct.unpack(record_format, record_bs))\n",
        "```\n",
        "\n",
        "三、不要依赖默认编码\n",
        "\n",
        "读写文本文件的时候最好要显示的指定编码方案，防止编码方案不匹配出现乱码或者错误；\n",
        "```\n",
        "open('cafe.txt', 'w', encoding='utf-8').write('café')\n",
        "\n",
        "fp = open('cafe.txt')\n",
        "print(fp)\n",
        "print(fp.read())\n",
        "```\n",
        "\n",
        "由于Linux的默认编码是UTF-8，所以运行结果正常\n",
        "```\n",
        "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='UTF-8'>\n",
        "café\n",
        "```\n",
        "但是在windows 10上执行就不这么幸运了，我们可以看到IO的默认编码方案是cp936\n",
        "\n",
        "```\n",
        "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='cp936'>\n",
        "caf茅\n",
        "```\n",
        "在Linux和windows上分别执行以下探测默认编码方案的代码\n",
        "```\n",
        "import sys, locale\n",
        "expressions = '''\n",
        "  locale.getpreferredencoding()\n",
        "  type(my_file)\n",
        "  my_file.encoding\n",
        "  sys.stdout.isatty()\n",
        "  sys.stdout.encoding\n",
        "  sys.stdin.isatty()\n",
        "  sys.stdin.encoding\n",
        "  sys.stderr.isatty()\n",
        "  sys.stderr.encoding\n",
        "  sys.getdefaultencoding()\n",
        "  sys.getfilesystemencoding()\n",
        "'''\n",
        "\n",
        "with open('encoding', 'w') as my_file:\n",
        "  for expression in expressions.split():\n",
        "    value = eval(expression)\n",
        "    print(expression.rjust(30), '->', repr(value))\n",
        "```\n",
        "在Ubuntu上执行，可以看到输出的都是UTF-8；\n",
        "\n",
        "```\n",
        " locale.getpreferredencoding() -> 'UTF-8'\n",
        "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
        "              my_file.encoding -> 'UTF-8'\n",
        "           sys.stdout.isatty() -> True\n",
        "           sys.stdout.encoding -> 'utf-8'\n",
        "            sys.stdin.isatty() -> True\n",
        "            sys.stdin.encoding -> 'utf-8'\n",
        "           sys.stderr.isatty() -> True\n",
        "           sys.stderr.encoding -> 'utf-8'\n",
        "      sys.getdefaultencoding() -> 'utf-8'\n",
        "   sys.getfilesystemencoding() -> 'utf-8'\n",
        "```\n",
        "\n",
        "在windows 10上执行，locale.getpreferredencoding()和my_file的编码都是cp936；\n",
        "\n",
        "```\n",
        "locale.getpreferredencoding() -> 'cp936'\n",
        "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
        "              my_file.encoding -> 'cp936'\n",
        "           sys.stdout.isatty() -> True\n",
        "           sys.stdout.encoding -> 'utf-8'\n",
        "            sys.stdin.isatty() -> True\n",
        "            sys.stdin.encoding -> 'utf-8'\n",
        "           sys.stderr.isatty() -> True\n",
        "           sys.stderr.encoding -> 'utf-8'\n",
        "      sys.getdefaultencoding() -> 'utf-8'\n",
        "   sys.getfilesystemencoding() -> 'utf-8'\n",
        "```\n",
        "\n",
        "如果没有指定编码方案，操作文本文件的时候默认使用locale.getpreferredencoding(),在windows10上将python的执行结果重定向到文件，可以看到sys.stdout.encoding变成了cp936；\n",
        "\n",
        "```\n",
        " locale.getpreferredencoding() -> 'cp936'\n",
        "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
        "              my_file.encoding -> 'cp936'\n",
        "           sys.stdout.isatty() -> False\n",
        "           sys.stdout.encoding -> 'cp936'\n",
        "            sys.stdin.isatty() -> True\n",
        "            sys.stdin.encoding -> 'utf-8'\n",
        "           sys.stderr.isatty() -> True\n",
        "           sys.stderr.encoding -> 'utf-8'\n",
        "      sys.getdefaultencoding() -> 'utf-8'\n",
        "   sys.getfilesystemencoding() -> 'utf-8'\n",
        "```\n",
        "\n",
        "python使用sys.getdefaultencoding()进行二进制数据与字符串之间的转换；\n",
        "sys.getfilesystemencoding（　）用于编解码文件名（不是文件内容）。把字符串参数作为文件名传给open（　）函数时就会使用它；\n",
        "\n",
        "四、规范化字符串之后进行比较\n",
        "\n",
        "\n",
        "因为Unicode有组合字符（变音符号和附加到前一个字符上的记号，打印时作为一个整体），所以字符串比较起来很复杂。\n",
        "```\n",
        "# 同样的一个字符会有不同的构成方式\n",
        "s1 = 'café'\n",
        "s2 = 'cafe\\u0301'\n",
        "print((s1, s2))\n",
        "print((len(s1), len(s2)))\n",
        "print(s1 == s2)\n",
        "```\n",
        "```\n",
        "('café', 'café')\n",
        "(4, 5)\n",
        "False\n",
        "```\n",
        "\n",
        "U+0301是COMBINING ACUTE ACCENT，加在“e”后面得到“é”。在Unicode标准中，'é'和'e\\u0301'这样的序列叫“标准等价物”（canonical equivalent），应用程序应该把它们视作相同的字符。但是，Python看到的是不同的码位序列，因此判定二者不相等。\n",
        "\n",
        "Python中unicodedata.normalize函数提供的Unicode规范化。这个函数的第一个参数是这4个字符串中的一个：'NFC'、'NFD'、'NFKC'和'NFKD'。NFC（Normalization Form C）使用最少的码位构成等价的字符串，而NFD把组合字符分解成基字符和单独的组合字符。这两种规范化方式都能让比较行为符合预期：\n",
        "```\n",
        "# normalize字符串再进行比较\n",
        "from unicodedata import normalize\n",
        "s1 = 'café'\n",
        "s2 = 'cafe\\u0301'\n",
        "print((s1, s2))\n",
        "print((len(s1), len(s2)))\n",
        "print(s1 == s2)\n",
        "\n",
        "s1_nfc_nor = normalize('NFC', s1)\n",
        "s2_nfc_nor = normalize('NFC', s2)\n",
        "print((s1_nfc_nor, s2_nfc_nor))\n",
        "print((len(s1_nfc_nor), len(s2_nfc_nor)))\n",
        "print(s1_nfc_nor == s2_nfc_nor)\n",
        "\n",
        "s1_nfd_nor = normalize('NFD', s1)\n",
        "s2_nfd_nor = normalize('NFD', s2)\n",
        "print((s1_nfd_nor, s2_nfd_nor))\n",
        "print((len(s1_nfd_nor), len(s2_nfd_nor)))\n",
        "print(s1_nfd_nor == s2_nfd_nor)\n",
        "\n",
        "# ('café', 'café')\n",
        "# (4, 5)\n",
        "# False\n",
        "# ('café', 'café')\n",
        "# (4, 4)\n",
        "# True\n",
        "# ('café', 'café')\n",
        "# (5, 5)\n",
        "# True\n",
        "```\n",
        "在另外两个规范化形式（NFKC和NFKD）的首字母缩略词中，字母K表示“compatibility”（兼容性）。这两种是较严格的规范化形式，对“兼容字符”有影响。虽然Unicode的目标是为各个字符提供“规范的”码位，但是为了兼容现有的标准，有些字符会出现多次。例如，虽然希腊字母表中有“μ”这个字母（码位是U+03BC，GREEK SMALL LETTER MU），但是Unicode还是加入了微符号'µ'（U+00B5），以便与latin1相互转换。因此，微符号是一个“兼容字符”。\n",
        "```\n",
        "# NFKC的规范化\n",
        "from unicodedata import normalize, name\n",
        "half = '½'\n",
        "print(len(half))\n",
        "print(hex(ord(half)))\n",
        "half_nor = normalize('NFKC', half)\n",
        "print(half_nor)\n",
        "print(type(half_nor))\n",
        "print(len(half_nor))\n",
        "for c in half_nor:\n",
        "  print(hex(ord(c)), end=' ')\n",
        "\n",
        "print()\n",
        "four_squared = '4²'\n",
        "four_squared_no = normalize('NFKC', four_squared)\n",
        "print(four_squared_no)\n",
        "\n",
        "micro = 'µ'\n",
        "micro_nor = normalize('NFKC', micro)\n",
        "print(micro_nor)\n",
        "print(ord(micro), ord(micro_nor))\n",
        "print(name(micro), name(micro_nor))\n",
        "\n",
        "# 1\n",
        "# 0xbd\n",
        "# 1⁄2\n",
        "# <class 'str'>\n",
        "# 3\n",
        "# 0x31 0x2044 0x32 \n",
        "# 42\n",
        "# μ\n",
        "# 181 956\n",
        "# MICRO SIGN GREEK SMALL LETTER MU\n",
        "```\n",
        "\n",
        "使用'1/2'替代'½'可以接受，微符号也确实是小写的希腊字母'µ'，但是把'4²'转换成'42'就改变原意了。某些应用程序可以把'4²'保存为'4<sup>2</sup>'，但是normalize函数对格式一无所知。因此，NFKC或NFKD可能会损失或曲解信息。\n",
        "\n",
        "大小写折叠其实就是把所有文本变成小写，再做些其他转换。这个功能由str.casefold（　）方法（Python 3.3新增）支持。对于只包含latin1字符的字符串s，s.casefold（　）得到的结果与s.lower（　）一样，唯有两个例外：微符号'µ'会变成小写的希腊字母“μ”（在多数字体中二者看起来一样）；德语Eszett（“sharp s”，ß）会变成“ss”。\n",
        "\n",
        "```\n",
        "# 大小写折叠\n",
        "micro = 'µ'\n",
        "print(name(micro))\n",
        "micro_cf = micro.casefold()\n",
        "print(name(micro_cf))\n",
        "print((micro, micro_cf))\n",
        "eszett = 'ß'\n",
        "print(name(eszett))\n",
        "eszett_cf = eszett.casefold()\n",
        "print((eszett, eszett_cf))\n",
        "\n",
        "# MICRO SIGN\n",
        "# GREEK SMALL LETTER MU\n",
        "# ('µ', 'μ')\n",
        "# LATIN SMALL LETTER SHARP S\n",
        "# ('ß', 'ss')\n",
        "```\n",
        "Google搜索涉及很多技术，其中一个显然是忽略变音符号（如重音符、下加符等），至少在某些情况下会这么做。去掉变音符号不是正确的规范化方式，因为这往往会改变词的意思，而且可能误判搜索结果。但是对现实生活却有所帮助：人们有时很懒，或者不知道怎么正确使用变音符号，而且拼写规则会随时间变化，因此实际语言中的重音经常变来变去。\n",
        "\n",
        "```\n",
        "# 极端规范化，去掉变音符号\n",
        "import unicodedata\n",
        "import string\n",
        "def shave_marks(txt):\n",
        "  txt_nor = normalize('NFD', txt)\n",
        "  txt_shaved = ''.join(c for c in txt_nor if not unicodedata.combining(c))\n",
        "  return normalize('NFC', txt_shaved)\n",
        "\n",
        "order = 'è ç í'\n",
        "print(shave_marks(order))\n",
        "\n",
        "greek = 'έ é'\n",
        "print(shave_marks(greek))\n",
        "\n",
        "\n",
        "def shave_marks_latin(txt):\n",
        "  txt_nor = normalize('NFD', txt)\n",
        "  latin_base = False\n",
        "  keep = []\n",
        "  for c in txt_nor:\n",
        "    if unicodedata.combining(c) and latin_base:\n",
        "      continue;\n",
        "    keep.append(c)\n",
        "    if not  unicodedata.combining(c):\n",
        "      latin_base = c in string.ascii_letters\n",
        "    \n",
        "  shaved = ''.join(keep)\n",
        "  return normalize('NFC', shaved)\n",
        "\n",
        "print(shave_marks_latin(order))\n",
        "print(shave_marks_latin(greek))\n",
        "\n",
        "\n",
        "# e c i\n",
        "# ε e\n",
        "# e c i\n",
        "# έ e\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A81vFmcm44W5"
      },
      "source": [
        "# normalize字符串再进行比较\n",
        "from unicodedata import normalize\n",
        "s1 = 'café'\n",
        "s2 = 'cafe\\u0301'\n",
        "print((s1, s2))\n",
        "print((len(s1), len(s2)))\n",
        "print(s1 == s2)\n",
        "\n",
        "s1_nfc_nor = normalize('NFC', s1)\n",
        "s2_nfc_nor = normalize('NFC', s2)\n",
        "print((s1_nfc_nor, s2_nfc_nor))\n",
        "print((len(s1_nfc_nor), len(s2_nfc_nor)))\n",
        "print(s1_nfc_nor == s2_nfc_nor)\n",
        "\n",
        "s1_nfd_nor = normalize('NFD', s1)\n",
        "s2_nfd_nor = normalize('NFD', s2)\n",
        "print((s1_nfd_nor, s2_nfd_nor))\n",
        "print((len(s1_nfd_nor), len(s2_nfd_nor)))\n",
        "print(s1_nfd_nor == s2_nfd_nor)\n",
        "\n",
        "# ('café', 'café')\n",
        "# (4, 5)\n",
        "# False\n",
        "# ('café', 'café')\n",
        "# (4, 4)\n",
        "# True\n",
        "# ('café', 'café')\n",
        "# (5, 5)\n",
        "# True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIcFkm9g3Vhk",
        "outputId": "d2011f7a-7ca6-40e6-e351-955ad7cfe4e7"
      },
      "source": [
        "# 同样的一个字符会有不同的构成方式\n",
        "s1 = 'café'\n",
        "s2 = 'cafe\\u0301'\n",
        "print((s1, s2))\n",
        "print((len(s1), len(s2)))\n",
        "print(s1 == s2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('café', 'café')\n",
            "(4, 5)\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjKm17V6t_F3"
      },
      "source": [
        "import sys, locale\n",
        "expressions = '''\n",
        "  locale.getpreferredencoding()\n",
        "  type(my_file)\n",
        "  my_file.encoding\n",
        "  sys.stdout.isatty()\n",
        "  sys.stdout.encoding\n",
        "  sys.stdin.isatty()\n",
        "  sys.stdin.encoding\n",
        "  sys.stderr.isatty()\n",
        "  sys.stderr.encoding\n",
        "  sys.getdefaultencoding()\n",
        "  sys.getfilesystemencoding()\n",
        "'''\n",
        "\n",
        "with open('encoding', 'w') as my_file:\n",
        "  for expression in expressions.split():\n",
        "    value = eval(expression)\n",
        "    print(expression.rjust(30), '->', repr(value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_AoYnAzsuOC"
      },
      "source": [
        "open('cafe.txt', 'w', encoding='utf-8').write('café')\n",
        "\n",
        "fp = open('cafe.txt')\n",
        "print(fp)\n",
        "print(fp.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFs0Jq97GZ_V",
        "outputId": "a9bae608-0ab0-4de6-a2e0-170d3cfcf961"
      },
      "source": [
        "import struct\n",
        "record_format = 'hd4s'\n",
        "pack_bytes = struct.pack(record_format, 7 , 3.14,b'gbye')\n",
        "print(type(pack_bytes))\n",
        "print(pack_bytes)\n",
        "with open('struct.b', 'wb') as fp:\n",
        "  fp.write(pack_bytes)\n",
        "\n",
        "record_size = struct.calcsize(record_format)\n",
        "with open('struct.b', 'rb') as fp:\n",
        "  record_bs = fp.read(record_size)\n",
        "  print(struct.unpack(record_format, record_bs))\n",
        "# print(struct.unpack(record_format, pack_bytes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'bytes'>\n",
            "b'\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1f\\x85\\xebQ\\xb8\\x1e\\t@gbye'\n",
            "(7, 3.14, b'gbye')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "dw-lU3BZ-vYy",
        "outputId": "e722fe14-ae40-4c4a-d903-ff73e188006f"
      },
      "source": [
        "s = 'helloèçí'\n",
        "b_arr = bytes(s, 'utf_8')\n",
        "print(type(b_arr))\n",
        "print(b_arr)\n",
        "for b in b_arr:\n",
        "  print(b, end=' ')\n",
        "\n",
        "print()\n",
        "print('element of bytes is int number', b_arr[0])\n",
        "\n",
        "print('splice of bytes is bytes',end = ' ' )\n",
        "b_arr_splice = b_arr[:1]\n",
        "print(b_arr_splice)\n",
        "\n",
        "num_b_arr = bytes([299])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'bytes'>\n",
            "b'hello\\xc3\\xa8\\xc3\\xa7\\xc3\\xad'\n",
            "104 101 108 108 111 195 168 195 167 195 173 \n",
            "element of bytes is int number 104\n",
            "splice of bytes is bytes b'h'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-b8f064f91cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_arr_splice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mnum_b_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: bytes must be in range(0, 256)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THg1BPWs8qsG",
        "outputId": "73db81a4-a9da-4fc5-c7c7-e16db2f2f7cf"
      },
      "source": [
        "s = 'èçí'\n",
        "\n",
        "print()\n",
        "for b in s.encode('utf_8'):\n",
        "  print(hex(b), end=' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0xc3 0xa8 0xc3 0xa7 0xc3 0xad "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS2uwYMx74El",
        "outputId": "0bce3c26-14e4-47f5-9070-0db928c64125"
      },
      "source": [
        "s = 'èçí'\n",
        "\n",
        "for b in s.encode('utf_16be'):\n",
        "  print(hex(b), end=' ')\n",
        "\n",
        "print()\n",
        "for b in s.encode('utf_16le'):\n",
        "  print(hex(b), end=' ')\n",
        "\n",
        "print()\n",
        "for b in s.encode('utf_16'):\n",
        "  print(hex(b), end=' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0x0 0xe8 0x0 0xe7 0x0 0xed \n",
            "0xe8 0x0 0xe7 0x0 0xed 0x0 \n",
            "0xff 0xfe 0xe8 0x0 0xe7 0x0 0xed 0x0 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKsdDEHKqFCO",
        "outputId": "e28e3f00-9329-4dc7-ed25-915d4e871468"
      },
      "source": [
        "s = 'èçí'\n",
        "\n",
        "for b in s.encode('utf_32be'):\n",
        "  print(hex(b), end=' ')\n",
        "\n",
        "print()\n",
        "for b in s.encode('utf_32le'):\n",
        "  print(hex(b), end=' ')\n",
        "\n",
        "print()\n",
        "for b in s.encode('utf_32'):\n",
        "  print(hex(b), end=' ')\n",
        "\n",
        "# print()\n",
        "# for b in s.encode('utf-8'):\n",
        "#   print(hex(b), end=' ')\n",
        "\n",
        "# print()\n",
        "# for b in s.encode('utf-16'):\n",
        "#   print(hex(b), end=' ')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0x0 0x0 0x0 0xe8 0x0 0x0 0x0 0xe7 0x0 0x0 0x0 0xed \n",
            "0xe8 0x0 0x0 0x0 0xe7 0x0 0x0 0x0 0xed 0x0 0x0 0x0 \n",
            "0xff 0xfe 0x0 0x0 0xe8 0x0 0x0 0x0 0xe7 0x0 0x0 0x0 0xed 0x0 0x0 0x0 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGzeEUnMnpg7",
        "outputId": "2fa1127b-5ca8-49d7-eb0f-c228267ef72e"
      },
      "source": [
        "s = 'è ç í'\n",
        "for c in s:\n",
        "  print(ord(c))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "232\n",
            "32\n",
            "231\n",
            "32\n",
            "237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "B6LdbDrAj3ir",
        "outputId": "53ac308a-0253-4eb7-cf97-cfb190461f98"
      },
      "source": [
        "s = b'é'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-b82fcf157fe5>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    s = b'é'\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m bytes can only contain ASCII literal characters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCHMdByTe-pY",
        "outputId": "966efbeb-4a29-4a30-cb15-bd02b1ed4304"
      },
      "source": [
        "s = 'hello world python'\n",
        "\n",
        "for c in s: \n",
        "  num = ord(c)\n",
        "  print(num, format(num, 'b'), bin(num))\n",
        "\n",
        "print(bin(ord('é')))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104 1101000 0b1101000\n",
            "101 1100101 0b1100101\n",
            "108 1101100 0b1101100\n",
            "108 1101100 0b1101100\n",
            "111 1101111 0b1101111\n",
            "32 100000 0b100000\n",
            "119 1110111 0b1110111\n",
            "111 1101111 0b1101111\n",
            "114 1110010 0b1110010\n",
            "108 1101100 0b1101100\n",
            "100 1100100 0b1100100\n",
            "32 100000 0b100000\n",
            "112 1110000 0b1110000\n",
            "121 1111001 0b1111001\n",
            "116 1110100 0b1110100\n",
            "104 1101000 0b1101000\n",
            "111 1101111 0b1101111\n",
            "110 1101110 0b1101110\n",
            "0b11101001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8DvJVYBdXw1",
        "outputId": "a812c8df-8581-4851-956e-f6617cbd6d2e"
      },
      "source": [
        "s = 'hello world python'\n",
        "for c in s:\n",
        "  print(c, end=' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "h e l l o   w o r l d   p y t h o n "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QyjZD5C7K2p"
      },
      "source": [
        "def printBytes(bs):\n",
        "    print()\n",
        "    for b in bs:\n",
        "        print(hex(b), end=' ')\n",
        "\n",
        "def printBytes(bs):\n",
        "    print([hex(i) for i in bs])\n",
        "\n",
        "\n",
        "s = 'How long is this?'\n",
        "s8 = s.encode('utf-8')\n",
        "s16 = s.encode('utf-16')\n",
        "s32 = s.encode('utf-32')\n",
        "# print((s8))\n",
        "printBytes(s8)\n",
        "# print(s16)\n",
        "printBytes(s16)\n",
        "# print(s32)\n",
        "printBytes(s32)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXd6DLrT7Qtj"
      },
      "source": [
        "b = b'\\xce\\xb3\\xce\\xb9\\xce\\xb1\\xce\\xbf\\xcf\\x8d\\xcf\\x81\\xcf\\x84\\xce\\xb9 - yogurt'\n",
        "print(type(b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eC7BwXBJpsU",
        "outputId": "87af736e-ede9-404d-ad33-2644319507c8"
      },
      "source": [
        "# ord\n",
        "\n",
        "s = 'café'\n",
        "print([hex(ord(c)) for c in s])\n",
        "print([hex(b) for b in s.encode('utf-8')])\n",
        "print([hex(b) for b in s.encode('utf-16')])\n",
        "print([hex(b) for b in s.encode('utf-32')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0x63', '0x61', '0x66', '0xe9']\n",
            "['0x63', '0x61', '0x66', '0xc3', '0xa9']\n",
            "['0xff', '0xfe', '0x63', '0x0', '0x61', '0x0', '0x66', '0x0', '0xe9', '0x0']\n",
            "['0xff', '0xfe', '0x0', '0x0', '0x63', '0x0', '0x0', '0x0', '0x61', '0x0', '0x0', '0x0', '0x66', '0x0', '0x0', '0x0', '0xe9', '0x0', '0x0', '0x0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5cKqeWLWH3v",
        "outputId": "0e6c7e40-ef8b-4fa5-e06c-0ff1a9b2e1ad"
      },
      "source": [
        "cafe = bytes('café', encoding='utf-8')\n",
        "cafe_arr = bytearray(cafe)\n",
        "print(cafe_arr)\n",
        "\n",
        "cafe_arr_splice = cafe_arr[-1:]\n",
        "print(cafe_arr_splice)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bytearray(b'caf\\xc3\\xa9')\n",
            "bytearray(b'\\xa9')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Po58PvBb6nC"
      },
      "source": [
        "import array\n",
        "numbers = array.array('h', [-2, -1, 0 , 1, 2])\n",
        "bs = bytes(numbers)\n",
        "print(bs)\n",
        "\n",
        "[print(i, end=' ') for i in bs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ45TW19_TAl",
        "outputId": "d13a9492-b1ec-49f7-965a-250c724ef920"
      },
      "source": [
        "open('cafe.txt', 'w', encoding='utf-8').write('café')\n",
        "\n",
        "fp = open('cafe.txt')\n",
        "print(fp)\n",
        "print(fp.read())\n",
        "\n",
        "# <_io.TextIOWrapper name='cafe.txt' mode='r' encoding='cp936'>\n",
        "# caf茅"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='UTF-8'>\n",
            "café\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRIQUw2QOfaZ"
      },
      "source": [
        "# NFKC的规范化\n",
        "from unicodedata import normalize, name\n",
        "half = '½'\n",
        "print(len(half))\n",
        "print(hex(ord(half)))\n",
        "half_nor = normalize('NFKC', half)\n",
        "print(half_nor)\n",
        "print(type(half_nor))\n",
        "print(len(half_nor))\n",
        "for c in half_nor:\n",
        "  print(hex(ord(c)), end=' ')\n",
        "\n",
        "print()\n",
        "four_squared = '4²'\n",
        "four_squared_no = normalize('NFKC', four_squared)\n",
        "print(four_squared_no)\n",
        "\n",
        "micro = 'µ'\n",
        "micro_nor = normalize('NFKC', micro)\n",
        "print(micro_nor)\n",
        "print(ord(micro), ord(micro_nor))\n",
        "print(name(micro), name(micro_nor))\n",
        "\n",
        "# 1\n",
        "# 0xbd\n",
        "# 1⁄2\n",
        "# <class 'str'>\n",
        "# 3\n",
        "# 0x31 0x2044 0x32 \n",
        "# 42\n",
        "# μ\n",
        "# 181 956\n",
        "# MICRO SIGN GREEK SMALL LETTER MU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeL7U_-hYmqX"
      },
      "source": [
        "# 大小写折叠\n",
        "micro = 'µ'\n",
        "print(name(micro))\n",
        "micro_cf = micro.casefold()\n",
        "print(name(micro_cf))\n",
        "print((micro, micro_cf))\n",
        "eszett = 'ß'\n",
        "print(name(eszett))\n",
        "eszett_cf = eszett.casefold()\n",
        "print((eszett, eszett_cf))\n",
        "\n",
        "# MICRO SIGN\n",
        "# GREEK SMALL LETTER MU\n",
        "# ('µ', 'μ')\n",
        "# LATIN SMALL LETTER SHARP S\n",
        "# ('ß', 'ss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bprsCsAabx0"
      },
      "source": [
        "# 通过规范化比较文本\n",
        "\n",
        "def nfc_equal(str1, str2):\n",
        "  return normalize('NFC', str1) == normalize('NFC', str2)\n",
        "\n",
        "def fold_equal(str1, str2):\n",
        "  return normalize('NFC', str1).casefold() == normalize('NFC', str2).casefold()\n",
        "\n",
        "s1 = 'café'\n",
        "s2 = 'cafe\\u0301'\n",
        "print(s1 == s2) \n",
        "\n",
        "print(nfc_equal(s1,s2))\n",
        "print(nfc_equal('A', 'a'))\n",
        "\n",
        "s3 = 'Straße'\n",
        "s4 = 'strasse'\n",
        "print(s3 == s4)\n",
        "print(nfc_equal(s3, s4))\n",
        "print(fold_equal(s3, s4))\n",
        "print(fold_equal(s1, s2))\n",
        "print(fold_equal('A', 'a'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRQCmTt1cpaO"
      },
      "source": [
        "# 极端规范化，去掉变音符号\n",
        "import unicodedata\n",
        "import string\n",
        "def shave_marks(txt):\n",
        "  txt_nor = normalize('NFD', txt)\n",
        "  txt_shaved = ''.join(c for c in txt_nor if not unicodedata.combining(c))\n",
        "  return normalize('NFC', txt_shaved)\n",
        "\n",
        "order = 'è ç í'\n",
        "print(shave_marks(order))\n",
        "\n",
        "greek = 'έ é'\n",
        "print(shave_marks(greek))\n",
        "\n",
        "\n",
        "def shave_marks_latin(txt):\n",
        "  txt_nor = normalize('NFD', txt)\n",
        "  latin_base = False\n",
        "  keep = []\n",
        "  for c in txt_nor:\n",
        "    if unicodedata.combining(c) and latin_base:\n",
        "      continue;\n",
        "    keep.append(c)\n",
        "    if not  unicodedata.combining(c):\n",
        "      latin_base = c in string.ascii_letters\n",
        "    \n",
        "  shaved = ''.join(keep)\n",
        "  return normalize('NFC', shaved)\n",
        "\n",
        "print(shave_marks_latin(order))\n",
        "print(shave_marks_latin(greek))\n",
        "\n",
        "\n",
        "# e c i\n",
        "# ε e\n",
        "# e c i\n",
        "# έ e\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}